# -*- coding: utf-8 -*-
"""Tarea v4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sXGwxtI0JNs1dBneeakPgx-m_sCuj9Ae

# **Librerias**
"""

#from __future__ import division
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from scipy import stats
from scipy.stats import norm, skew

import sklearn
from sklearn.pipeline import Pipeline, FeatureUnion
from sklearn.impute import SimpleImputer, MissingIndicator
from sklearn.preprocessing import FunctionTransformer, LabelEncoder, Normalizer, StandardScaler, OneHotEncoder
from sklearn.base import BaseEstimator, TransformerMixin, ClassifierMixin, clone
import sklearn_pandas
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score,train_test_split
from scipy import stats
from sklearn.linear_model import LinearRegression
from scipy.special import boxcox1p
import csv
import seaborn as sns

import sys
import time


import warnings
warnings.filterwarnings('ignore')

"""# **Importar Datos**"""

train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/TFM/Data/train.csv')
test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/TFM/Data/test.csv')

# Junto los dos dataframes para hacer el EDA
junto_df = pd.concat((train_df.loc[:,:], test_df.loc[:, :]))

train_df.head()

train_df.tail()

"""# **Análisis exploratorio de los datos (EDA)**

**Número de documentos y columnas**
"""

print("Tenemos un conjunto de {} documentos (train)".format(len(train_df)))
print("El dataframe tiene {} columnas (train)".format(train_df.shape[1]))

print("Tenemos un conjunto de {} documentos (test)".format(len(test_df)))
print("El dataframe tiene {} columnas (test)".format(train_df.shape[1]))

"""**Información estadística básica de los datos**"""

train_df.describe()

"""**Información de las columnas**"""

train_df.info()

"""Observo que el conjunto de datos tiene en total 81 columnas, de las cuales 38 son numéricas."""

correlacion = train_df.corr()

plt.subplots(figsize = (25, 25))
sns.heatmap(correlacion, annot = True)

"""Al desplegar la correlación entre las columnas, observo que hay muchas correlaciones, así que debo tener cuidado.

A continuación, me enfoco en las 10 variables que tienen mas correlación con la variable objetivo que es 'SalePrice'
"""

correlacion_target = correlacion['SalePrice'].sort_values(ascending = False).head(10).index
correlacion_SalePrice = train_df[correlacion_target].corr()

plt.subplots(figsize = (20, 20))
sns.heatmap(correlacion_SalePrice, annot = True)

"""A continuación reviso los datos de las variables de arriba con 'SalePrice' usando el grafico de scatter."""

fig, axs = plt.subplots(2, 5, figsize = (20, 15))
x, y = 0, 0

for col in correlacion_target:
  axs[x, y].scatter(x = train_df[col], y = train_df['SalePrice'])
  axs[x, y].set_xlabel(col)
  axs[x, y].set_ylabel('SalePrice')  
  
  x += 1  
  
  if x == 2:
    x = 0
    y += 1

"""Observamos lo siguiente:



*   Se puede ver que los datos TotRmsAbvGrd, OverallQual, GarageCars y FullBath son datos no numéricos
*   Los datos de GrLivArea, 1stFirSF y TotalBsmtSF muestran un patrón lineal para SalePrice.

**A continuación, reviso la variable objetivo que es 'SalePrice'**
"""

train_df['SalePrice'].describe()

sns.boxplot(train_df['SalePrice'])

"""En la grafica observo que hay 2 outliers (valores fuera de rango) con valor mayor a 700000.

A continuación analizaré la distribución.

"""

asimetria = train_df.SalePrice.skew()
kurtosis = train_df.SalePrice.kurt()

print("La asimetria es de {}".format(asimetria))
print("La kurtosis es de {}".format(kurtosis))

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

sns.set_style("whitegrid")
#sns.set(rc={'axes.facecolor':'white', 'figure.facecolor':'white'})
#plt.style.use('ggplot')

plt.figure(figsize=(10,5))

plt.subplot(1,2,1)
sns.distplot(train_df.SalePrice, bins=50)
plt.title('Original')

plt.subplot(1,2,2)
sns.distplot(np.log1p(train_df.SalePrice), bins=50)
plt.title('Log')

plt.tight_layout()

"""Confirmo una distribución sesgada a la derecha, así que le aplico una transformación logaritmica para normalizarla.

**Análisis de resgistos con NaN o Missing**
"""

valores_na = [f for f in train_df.columns if train_df[f].isnull().sum()>1]
valores_na

lista_na = []
for i in valores_na: 
    x= np.round(train_df[i].isnull().mean(),2)
    print(i,  x,'% missing values')
    lista_na.append(x)

plt.figure(figsize = (10,10))
plt.pie(lista_na,labels = valores_na,autopct='%.2f' )
plt.show()

num_nan = train_df.isna().sum() / train_df.shape[0]

plt.figure(figsize=(8, 5))
sns.set(font_scale=1.2)
num_nan[num_nan > 0.01].plot(kind = "barh")
plt.title("Columnas con el mayor numero de valores NaN")

"""**Analizando las variables numéricas**"""

quantitative = [f for f in train_df.columns if train_df.dtypes[f] != "O"]

f = pd.melt(train_df, value_vars=quantitative)
g = sns.FacetGrid(f, col="variable",  col_wrap=5, sharex=False, sharey=False)
g = g.map(sns.distplot, "value")

"""Observo que ninguna de las variables cuantitativas tienen una distribución normal.

Algunas variables independientes parecen buenas candidatas para la transformación logaritmica: 'TotalBsmtSF', 'KitchenAbvGr', 'LotFrontage', 'LotArea' y otras.

Si bien ganar en la transformación de regresión suavizará algunas irregularidades que podrían ser importantes, como una gran cantidad de casas con 0 2ndFlrSF. Tales irregularidades son buenas candidatas para la construcción de características.
"""

numeric_na_features = train_df.select_dtypes(np.number).loc[:, train_df.isna().sum() > 0].columns
numeric_na_features

numeric_na_features = ['LotFrontage', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF',
       'TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath', 'GarageYrBlt',
       'GarageCars', 'GarageArea']

for feature in numeric_na_features:
    df = train_df.copy()
    df[feature] = np.log(df[feature])
    df.boxplot(column=feature)
    plt.ylabel(feature)
    plt.title(f"{feature}'s Outliers'")
    plt.show()

"""Dado que las características numéricas anteriores tienen muchos valores atípicos, podemos completar los valores faltantes usando su media

**Análisis de la variable 'GrLivArea'**
"""

analisis_GrLivArea = pd.concat([train_df["SalePrice"], train_df['GrLivArea']], axis=1)
analisis_GrLivArea.head()

analisis_GrLivArea.plot.scatter(x='GrLivArea', y='SalePrice')

"""**Análisis de columnas con valores NULL** """

total_null = train_df.isnull().sum().sort_values(ascending = False)
porcentaje_null = (total_null / train_df.isnull().count()).sort_values(ascending = False)

valores_null = pd.concat([total_null, porcentaje_null], axis = 1, keys = ['Total de Nulos', 'Porcentaje'])
valores_null.head(20)

"""*   Las columnas **'PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu' y 'LotFrontage'** tienen un porcentaje dominante porque es probable que cuando las personas compran una casa no presten atención a este aspecto y finalmente los datos anteriores son menos importantes. **Decido eliminar estas columnas.**
*   Las columnas **'GarageCond', 'GarageType', 'GarageYrBlt', 'GarageFinish' y 'GarageQual'** tienen el mismo porcentaje. **Decido eliminar estas columnas.** considerado que son representadas por las columnas **'GarageArea' y 'GarageCars'** que tienen alta correlación con 'SalePrice'.
*   Las columnas **'MasVnrArea' y 'MasVnrType'** puedo eliminarlas porque tienen correlación positiva con las columnas **'OverallQual' y 'YearBuilt'**.
*   La columna **'Electrical'** decido no eliminarla porque solo tiene 1 valor NULL.


"""

train_df.shape

train_df_dummies = pd.get_dummies(train_df)
train_df_dummies['SalePrice']

"""# **Data Preprocessing and Data Cleaning**"""

train_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/TFM/Data/train.csv')
test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/TFM/Data/test.csv')

# Junto los dos dataframes para hacer el EDA
junto_df = pd.concat((train_df.loc[:,:], test_df.loc[:, :]))

sns.set_style("whitegrid")

target = train_df['SalePrice']
target_log = np.log1p(train_df['SalePrice'])

"""**Elimino outliers**"""

#Elimino outliers solo de train
#print(train_df[train_df['SalePrice'] > 700000].index)
#train_df = train_df.drop(691)
#train_df = train_df.drop(1182)

"""Para aplicar las transformaciones, utilizaré el dataset donde tengo junto train y test."""

train_df = train_df.drop(["SalePrice"], axis=1)
junto_df = pd.concat([train_df, test_df], ignore_index=True)

"""Divido el dataset en 2: El primero tendrá las variables categóricas y el segundo las variables numericas"""

categoricas = [col for col in junto_df.columns.values if junto_df[col].dtype == 'object']

categoricas_df = junto_df[categoricas]
numericas_df = junto_df.drop(categoricas, axis=1)

numericas_df.head(1)

numericas_df.describe()

categoricas_df.head(1)

"""**Reducción de Asimetrías para variables numéricas**"""

num_skew = numericas_df.apply(lambda x: skew(x.dropna()))
num_skew = num_skew[num_skew > 0.75]

#Aplico Log+1a a las variables con sesgo > 0.75
numericas_df[num_skew.index] = np.log1p(numericas_df[num_skew.index])

num_skew

"""**Manejo de valores Missing: Variables Numericas**"""

numericas_df.isnull().sum()

data_len = numericas_df.shape[0]

for col in numericas_df.columns:
  total_null = numericas_df[col].isnull().sum()
  porcentaje_null = ((total_null / numericas_df[col].isnull().count())*100)
  print("{} - porcentaje nulos: {} ".format(col, porcentaje_null))


  if porcentaje_null > 80:
    print("Eliminando columna: {}".format(col))

numericas_df = numericas_df.fillna(numericas_df[col].median())



#for col in numericas_df.columns.values:
    #missing_values = numericas_df[col].isnull().sum()
    #print("{} - missing values: {} ({:0.2f}%)".format(col, missing_values, missing_values/data_len*100))
    #porcentaje_null = (total_null / numericas_df[col].isnull().count()) 
    #print("{} - porcentaje nulos: {} ".format(col, porcentaje_null))

    # drop si tiene mas de 50 valores valores missing
    #if porcentaje_null > .80:
        #print("Eliminando columna: {}".format(col))
        #numericas_df = numericas_df.drop(col, axis = 1)



#numericas_df = numericas_df.fillna(numericas_df[col].median())

numericas_df.isnull().sum()

numericas_df.describe()

"""**Manejo de valores Missing: Variables Categóricas**"""

categoricas_df.isnull().sum()

data_len = categoricas_df.shape[0]

for col in categoricas_df.columns:
  total_null = categoricas_df[col].isnull().sum()
  porcentaje_null = ((total_null / categoricas_df[col].isnull().count())*100)
  
  if (porcentaje_null > 80):
    print("Eliminando columna: {} - porcentaje nulos: {}".format(col,porcentaje_null))
    categoricas_df = categoricas_df.drop(col, axis = 1)

categoricas_df = categoricas_df.fillna('No aplica')



#data_len = categoricas_df.shape[0]

#for col in categoricas_df.columns.values:
#    missing_values = categoricas_df[col].isnull().sum()
#    #print("{} - missing values: {} ({:0.2f}%)".format(col, missing_values, missing_values/data_len*100))

#    # drop si tiene mas de 50 valores missing    
#    if missing_values > 50:
#        print("Eliminando columna: {}".format(col))
#        categoricas_df = categoricas_df.drop(col, axis = 1)


#categoricas_df = categoricas_df.fillna('No aplica')

categoricas_df.isnull().sum()

categoricas_df.describe()

categoricas_df_dummies = pd.get_dummies(categoricas_df)
categoricas_df_dummies.shape

numericas_df.shape

categoricas_df.shape

datos = pd.concat([numericas_df, categoricas_df_dummies], axis=1)
#datos = pd.concat([numericas_df, categoricas_df], axis=1)

datos

train_bis = datos.iloc[:len(train_df)]
train_bis = train_bis.join(target_log)

test_bis = datos.iloc[len(train_df):]

train_bis.to_pickle("/content/drive/MyDrive/Colab Notebooks/TFM/Data/Datatrain_clean.pkl")
test_bis.to_pickle("/content/drive/MyDrive/Colab Notebooks/TFM/Data/Datatest_clean.pkl")

datos.columns.values

"""# **Model Training** """

train_bis = pd.read_pickle("/content/drive/MyDrive/Colab Notebooks/TFM/Data/Datatrain_clean.pkl")
test_bis = pd.read_pickle("/content/drive/MyDrive/Colab Notebooks/TFM/Data/Datatest_clean.pkl")

"""**Divido nuevamente el dataset**"""

X_train = train_bis[train_bis.columns.values[1:-1]] #[:-1]
y_train = train_bis[train_bis.columns.values[-1]]

# Quito ID
X_test = test_bis[test_bis.columns.values[1:]] #[:]

X_train

from sklearn.model_selection import train_test_split
# Selecciono 80-20
X_train1, X_test1, y_train1, y_test1 = train_test_split(X_train, y_train, test_size = 0.2, random_state = 10)

"""**El primer modelo lo haré con Random Forest (LB: 0.14797)**"""

# Commented out IPython magic to ensure Python compatibility.
from sklearn.ensemble import RandomForestRegressor
import matplotlib.pyplot as plt

# %matplotlib inline

modelo_RF = RandomForestRegressor(n_estimators=500, n_jobs=-1)

modelo_RF.fit(X_train1, y_train1)
rf_pred = modelo_RF.predict(X_test1)

#Gráfica
sns.set(font_scale=1.5)
plt.figure(figsize=(10, 5))
plt.scatter(y_test1, rf_pred, s=20)
plt.title('Predicted vs. Actual')
plt.xlabel('Actual Sale Price')
plt.ylabel('Predicted Sale Price')

plt.plot([min(y_test1), max(y_test1)], [min(y_test1), max(y_test1)])
plt.tight_layout()

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import math
MSE_RF = mean_squared_error(y_test1, rf_pred)
RMSE_RF = math.sqrt(MSE_RF)

print("RMSE-{}-CV({})={:06.5f}".format('modelo_RF', '7', RMSE_RF))
print('MSE:', MSE_RF)
print('MAE:', mean_absolute_error(y_test1, rf_pred))
print('R2: ',  r2_score(y_test1, rf_pred) * 100)

#Aplico Cross-Validation para validar overfiting
RF_CV = cross_val_score(modelo_RF, X_train1, y_train1, scoring="neg_mean_squared_error", cv = 7)
print(RF_CV)

print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_RF', '7', RF_CV.mean()))
print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_RF', '7', RF_CV.std()))

rf_pred_log = modelo_RF.predict(X_test)

#Genero el archivo test con la predicción
final_rf = pd.DataFrame({'Id':test_bis['Id'], 'SalePrice':np.expm1(rf_pred_log)})
final_rf.to_csv("/content/drive/MyDrive/Colab Notebooks/TFM/Data/final_rf.csv", index=False)

"""**El segundo modelo es Regresión Lineal con regularización - RIDGE (LB: 5.08556)**"""

from sklearn.linear_model import Ridge, RidgeCV
modelo_ridge = Ridge()
alphas = [0.05, 0.1, 0.3, 1, 3, 5, 10, 15, 30, 50, 75]

def calcula_alpha(model):
    res_alpha = np.sqrt(-cross_val_score(model, X_train, y_train, scoring="neg_mean_squared_error", cv = 7))
    return(res_alpha)

cv_ridge = [calcula_alpha(Ridge(alpha = alpha)).mean() for alpha in alphas]

cv_ridge

cv_ridge = pd.Series(cv_ridge, index = alphas)
cv_ridge.plot(title = "Validation")
sns.set(font_scale=1.5)
plt.xlabel("alpha")
plt.ylabel("rmse")

cv_ridge.min()

"""Compruebo que el error mas pequeño es con alpha=10"""

cv_ridge

modelo_ridge = Ridge(alpha = 10).fit(X_train1, y_train1)
ridge_pred = modelo_ridge.predict(X_test1)

#Gráfica
sns.set(font_scale=1.5)
plt.figure(figsize=(10, 5))
plt.scatter(y_test1, ridge_pred, s=20)
plt.title('Predicted vs. Actual')
plt.xlabel('Actual Sale Price')
plt.ylabel('Predicted Sale Price')

plt.plot([min(y_test1), max(y_test1)], [min(y_test1), max(y_test1)])
plt.tight_layout()

from sklearn.metrics import mean_squared_error
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import math
MSE_ridge = mean_squared_error(y_test1, ridge_pred)
RMSE_ridge = math.sqrt(MSE_ridge)

print("RMSE-{}-CV({})={:06.5f}".format('modelo_ridge', '7', RMSE_ridge))
print('MSE:', MSE_ridge)
print('MAE:', mean_absolute_error(y_test1, ridge_pred))
print('R2: ',  r2_score(y_test1, ridge_pred) * 100)

#Aplico Cross-Validation para validar overfiting
ridge_CV = cross_val_score(modelo_ridge, X_train1, y_train1, scoring="neg_mean_squared_error", cv = 7)
print(ridge_CV)

print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_ridge', '7', ridge_CV.mean()))
print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_ridge', '7', ridge_CV.std()))

ridge_pred_log = modelo_ridge.predict(X_test)

#Genero el archivo test con la predicción
final_ridge = pd.DataFrame({'Id':test_bis['Id'], 'SalePrice':np.expm1(ridge_pred_log)})
final_ridge.to_csv("/content/drive/MyDrive/Colab Notebooks/TFM/Data/final_ridge.csv", index=False)

"""**Linear regression with regularisation - LASSO (LB: 3.70863)**"""

from sklearn.linear_model import LassoCV
modelo_lasso = LassoCV(alphas = [1, 0.1, 0.001, 0.0005]).fit(X_train1, y_train1)

modelo_lasso.fit(X_train1, y_train1)
lasso_pred = modelo_lasso.predict(X_test1)

#Gráfica
plt.figure(figsize=(10, 5))
plt.scatter(y_test1, lasso_pred, s=20)
plt.title('Predicted vs. Actual')
plt.xlabel('Actual Sale Price')
plt.ylabel('Predicted Sale Price')

plt.plot([min(y_test1), max(y_test1)], [min(y_test1), max(y_test1)])
plt.tight_layout()

MSE_lasso = mean_squared_error(y_test1, lasso_pred)
RMSE_lasso = math.sqrt(MSE_lasso)

print("RMSE-{}-CV({})={:06.5f}".format('modelo_lasso', '7', RMSE_lasso))
print('MSE:', MSE_lasso)
print('MAE:', mean_absolute_error(y_test1, lasso_pred))
print('R2: ',  r2_score(y_test1, lasso_pred) * 100)

#Aplico Cross-Validation para validar overfiting
lasso_CV = cross_val_score(modelo_lasso, X_train1, y_train1, scoring="neg_mean_squared_error", cv = 7)
print(lasso_CV)

print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_lasso', '7', lasso_CV.mean()))
print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_lasso', '7', lasso_CV.std()))

lasso_pred_log = modelo_lasso.predict(X_test)
final_lasso = pd.DataFrame({'Id':test_bis['Id'], 'SalePrice':np.expm1(lasso_pred_log)})
final_lasso.to_csv("/content/drive/MyDrive/Colab Notebooks/TFM/Data/final_lasso.csv", index=False)
final_lasso.head()

"""**El cuarto modelo es Xgboost (LB: 0.13349)**"""

import xgboost as xgb

dtrain = xgb.DMatrix(X_train1, label = y_train1)
dtest = xgb.DMatrix(X_test1)

params = {"max_depth":2, "eta":0.1}
modelo_xgb = xgb.cv(params, dtrain,  num_boost_round=500, early_stopping_rounds=100)

modelo_xgb.loc[30:,["test-rmse-mean", "train-rmse-mean"]].plot()

modelo_xgb = xgb.XGBRegressor(n_estimators=360, max_depth=2, learning_rate=0.1)

modelo_xgb.fit(X_train1, y_train1)
xgb_pred = modelo_xgb.predict(X_test1)

#Gráfica
sns.set(font_scale=1.5)
plt.figure(figsize=(10, 5))
plt.scatter(y_test1, xgb_pred, s=20)
plt.title('Predicted vs. Actual')
plt.xlabel('Actual Sale Price')
plt.ylabel('Predicted Sale Price')

plt.plot([min(y_test1), max(y_test1)], [min(y_test1), max(y_test1)])
plt.tight_layout()

MSE_xgb = mean_squared_error(y_test1, xgb_pred)
RMSE_xgb = math.sqrt(MSE_xgb)

print("RMSE-{}-CV({})={:06.5f}".format('modelo_xgb', '7', RMSE_xgb))
print('MSE:', MSE_xgb)
print('MAE:', mean_absolute_error(y_test1, xgb_pred))
print('R2: ',  r2_score(y_test1, xgb_pred) * 100)

#Aplico Cross-Validation para validar overfiting
xgb_CV = cross_val_score(modelo_xgb, X_train1, y_train1, scoring="neg_mean_squared_error", cv = 7)
print(xgb_CV)

print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_xgb', '7', xgb_CV.mean()))
print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_xgb', '7', xgb_CV.std()))

xgb_pred_log = modelo_xgb.predict(X_test)
final_xgboost = pd.DataFrame({'Id':test_bis['Id'], 'SalePrice':np.expm1(xgb_pred_log)})
final_xgboost.to_csv("/content/drive/MyDrive/Colab Notebooks/TFM/Data/final_xgboost.csv", index=False)
final_xgboost.head()

"""**El quinto modelo es GradientBoosting (LB: 0.22494)**"""

from sklearn.ensemble import GradientBoostingRegressor
parametros = {'n_estimators': 100, 'max_depth': 10, 'min_samples_split': 2,
          'learning_rate': 0.01, 'loss': 'ls'}

modelo_gbr = GradientBoostingRegressor(**parametros)
modelo_gbr.fit(X_train1, y_train1)
gbr_pred = modelo_gbr.predict(X_test1)

#Gráfica
sns.set(font_scale=1.5)
plt.figure(figsize=(10, 5))
plt.scatter(y_test1, gbr_pred, s=20)
plt.title('Predicted vs. Actual')
plt.xlabel('Actual Sale Price')
plt.ylabel('Predicted Sale Price')

plt.plot([min(y_test1), max(y_test1)], [min(y_test1), max(y_test1)])
plt.tight_layout()

MSE_gbr = mean_squared_error(y_test1, gbr_pred)
RMSE_gbr = math.sqrt(MSE_gbr)

print("RMSE-{}-CV({})={:06.5f}".format('modelo_gbr', '7', RMSE_gbr))
print('MSE:', MSE_gbr)
print('MAE:', mean_absolute_error(y_test1, gbr_pred))
print('R2: ',  r2_score(y_test1, gbr_pred) * 100)

#Aplico Cross-Validation para validar overfiting
gbr_CV = cross_val_score(modelo_gbr, X_train1, y_train1, scoring="neg_mean_squared_error", cv = 7)
print(gbr_CV)

print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_gbr', '7', gbr_CV.mean()))
print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_gbr', '7', gbr_CV.std()))

gbr_pred_log = modelo_gbr.predict(X_test)
final_gbr = pd.DataFrame({'Id':test_bis['Id'], 'SalePrice':np.expm1(gbr_pred_log)})
final_gbr.to_csv("/content/drive/MyDrive/Colab Notebooks/TFM/Data/final_gbr.csv", index=False)
final_gbr.head()

"""**Comparativo de resultados con los modelos anteriores**"""

print('RF - ', RMSE_RF)
print('Ridge - ', RMSE_ridge)
print('XGB - ', RMSE_xgb)
print('GBR - ', RMSE_gbr)
print('Gradient - ', RMSE_gbr)
print('Lasso - ', RMSE_lasso)

pred_rf = np.expm1(modelo_RF.predict(X_test))
pred_ridge = np.expm1(modelo_ridge.predict(X_test))
pred_xgb = np.expm1(modelo_xgb.predict(X_test))
pred_gbr = np.expm1(modelo_gbr.predict(X_test))
pred_lasso = np.expm1(modelo_lasso.predict(X_test))

predictions = pd.DataFrame({"rf":pred_rf,                             
                            "ridge":pred_ridge,
                            "xgb": pred_xgb,
                            "Gradient":pred_gbr,
                            "Lasso":pred_lasso})
#predictions.plot(x = "rf", y = "ridge", kind = "scatter")
predictions.head()

"""**Combinación de los 2 mejores: Random Forest + Xgboost (LB: Score: 0.13145)**

Los 2 modelos los selecciono en base al score que me dió Kaggle
"""

combinacio_rf_xgb = 0.4*pred_rf + 0.6*pred_xgb
final_rf_xgb = pd.DataFrame({'Id':test_bis['Id'], 'SalePrice':combinacio_rf_xgb})
final_rf_xgb.to_csv("/content/drive/MyDrive/Colab Notebooks/TFM/Data/final_rf_xgb.csv", index=False)
final_rf_xgb.head()

"""# **Hiperparámetros**

A continuación, los hiperparámetros de los modelos individuales los optimizaré con validación cruzada.
"""

from matplotlib import pyplot

from sklearn.model_selection import train_test_split
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error
from sklearn.metrics import make_scorer

def rmse_cv(modelo, X_train1, y_train1):
    kfold = KFold(n_splits=folds, random_state=seed, shuffle=True)
    rmse = np.sqrt(-cross_val_score(modelo, X_train1, y_train1, scoring="neg_mean_squared_error", cv = kfold))
    return(rmse)

def rmse(y_true, y_pred):
    return np.sqrt(mean_squared_error(y_true, y_pred))

folds = 5
seed = 7

"""**Decision Tree Regressor con hiperparámetros (LB: )**"""

from sklearn.tree import DecisionTreeRegressor


# tunning
modelo_DTR_hp = DecisionTreeRegressor()

param_grid = {
        'max_depth': range(2, 11, 2), 
        'min_samples_split': [2, 3, 4],
        'min_samples_leaf': range(1, 20, 5),
        'max_leaf_nodes': range(2, 20, 5)
}

kfold = KFold(n_splits=folds, random_state=seed, shuffle=True)

scorer = make_scorer(rmse, greater_is_better=False)
grid_search = GridSearchCV(modelo_DTR_hp, param_grid, n_jobs=-1, cv=kfold, verbose=1, scoring=scorer)
grid_result = grid_search.fit(X_train1, y_train1)

means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']

for mean, stdev, param in zip(means, stds, params):
  print("%f (%f) with: %r" % (mean, stdev, param))
  print("{:06.5f} ({:06.5f}) with {}".format(mean, stdev, param))

# Resultados
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

# Modelo
modelo_DTR_hp = DecisionTreeRegressor(max_depth=6, min_samples_split=2, max_leaf_nodes=17, min_samples_leaf=16)

# Fit & Predict
modelo_DTR_hp.fit(X_train1, y_train1)
DTR_hp_pred = modelo_DTR_hp.predict(X_test1)

#Gráfica
sns.set(font_scale=1.5)
plt.figure(figsize=(10, 5))
plt.scatter(y_test1, DTR_hp_pred, s=20)
plt.title('Predicted vs. Actual')
plt.xlabel('Actual Sale Price')
plt.ylabel('Predicted Sale Price')

plt.plot([min(y_test1), max(y_test1)], [min(y_test1), max(y_test1)])
plt.tight_layout()

RMSE_DTR_hp = rmse_cv(modelo_DTR_hp, X_train1, y_train1)

print("RMSE-{}-CV({})={:06.5f}+-{:06.5f}".format('modelo_DTR_hp', folds, RMSE_DTR_hp.mean(), RMSE_DTR_hp.std()))
print('MAE:', mean_absolute_error(y_test1, DTR_hp_pred))
print('R2: ',  r2_score(y_test1, DTR_hp_pred) * 100)

#Aplico Cross-Validation para validar overfiting
DTR_hp_CV = cross_val_score(modelo_DTR_hp, X_train1, y_train1, scoring="neg_mean_squared_error", cv = 7)
print(DTR_hp_CV)

print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_DTR_hp', '7', DTR_hp_CV.mean()))
print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_DTR_hp', '7', DTR_hp_CV.std()))

# Predicción
DTR_hp_pred_log = modelo_DTR_hp.predict(X_test)
final_DTR_hp = pd.DataFrame({'Id':test_bis['Id'], 'SalePrice':np.expm1(DTR_hp_pred_log)})
final_DTR_hp.to_csv("/content/drive/MyDrive/Colab Notebooks/TFM/Data/final_dtr_hp.csv", index=False)
final_DTR_hp.head()

"""**Random Forest Regressor con hiperparámetros (LB: 0.14227)**"""

# tunning
modelo_RF_hp = RandomForestRegressor()


param_grid = {
    'bootstrap': [True, False],
    'n_estimators': [100, 500, 1000],
    'max_features': [5, 50]
}

kfold = KFold(n_splits=folds, random_state=seed, shuffle=True)

scorer = make_scorer(rmse, greater_is_better=False)
grid_search = GridSearchCV(modelo_RF_hp, param_grid, n_jobs=-1, cv=kfold, verbose=1, scoring=scorer)
grid_result = grid_search.fit(X_train1, y_train1)

means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']

for mean, stdev, param in zip(means, stds, params):
    print("{:06.5f} ({:06.5f}) with {}".format(mean, stdev, param))

# Resultados
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

# Modelo
modelo_RF_hp = RandomForestRegressor(max_features=50, n_estimators=500, bootstrap=False)

# Fit & Predict
modelo_RF_hp.fit(X_train1, y_train1)
RF_hp_pred = modelo_RF_hp.predict(X_test1)

#Gráfica
sns.set(font_scale=1.5)
plt.figure(figsize=(10, 5))
plt.scatter(y_test1, RF_hp_pred, s=20)
plt.title('Predicted vs. Actual')
plt.xlabel('Actual Sale Price')
plt.ylabel('Predicted Sale Price')

plt.plot([min(y_test1), max(y_test1)], [min(y_test1), max(y_test1)])
plt.tight_layout()

RMSE_RF_hp = rmse_cv(modelo_RF_hp, X_train1, y_train1)

print("RMSE-{}-CV({})={:06.5f}+-{:06.5f}".format('modelo_RF_hp', folds, RMSE_RF_hp.mean(), RMSE_RF_hp.std()))
print('MAE:', mean_absolute_error(y_test1, RF_hp_pred))
print('R2: ',  r2_score(y_test1, RF_hp_pred) * 100)

#Aplico Cross-Validation para validar overfiting
RF_hp_CV = cross_val_score(modelo_RF_hp, X_train1, y_train1, scoring="neg_mean_squared_error", cv = 7)
print(RF_hp_CV)

print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_DTR_hp', '7', RF_hp_CV.mean()))
print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_DTR_hp', '7', RF_hp_CV.std()))

# Predicción
RF_hp_pred_log = modelo_RF_hp.predict(X_test)
final_RF_hp = pd.DataFrame({'Id':test_bis['Id'], 'SalePrice':np.expm1(RF_hp_pred_log)})
final_RF_hp.to_csv("/content/drive/MyDrive/Colab Notebooks/TFM/Data/final_RF_hp.csv", index=False)
final_RF_hp.head()

"""**Xgboost con hiperparámetros (LB: )**"""

# tunning
modelo_xgb_hp = xgb.XGBRegressor()

param_grid = {
    'max_depth': [2, 4], 
    'learning_rate': [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3],
    'min_child_weight': range(1, 10, 2),
    'n_estimators': range(50, 300, 50),
    'objective': ['reg:linear']
}

kfold = KFold(n_splits=folds, random_state=seed, shuffle=True)

scorer = make_scorer(rmse, greater_is_better=False)
grid_search = GridSearchCV(modelo_xgb_hp, param_grid, n_jobs=-1, cv=kfold, verbose=1, scoring=scorer)
grid_result = grid_search.fit(X_train1, y_train1)

means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']

for mean, stdev, param in zip(means, stds, params):
    print("{:06.5f} ({:06.5f}) with {}".format(mean, stdev, param))

# Resultados
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

# Model
modelo_xgb_hp = xgb.XGBRegressor(n_estimators=250,learning_rate=0.2,max_depth=2,min_child_weight=1,objective='reg:linear')

# Fit & Predict
modelo_xgb_hp.fit(X_train1, y_train1, verbose=True)
xgb_hp_pred = modelo_xgb_hp.predict(X_test1)

#Gráfica
sns.set(font_scale=1.5)
plt.figure(figsize=(10, 5))
plt.scatter(y_test1, xgb_hp_pred, s=20)
plt.title('Predicted vs. Actual')
plt.xlabel('Actual Sale Price')
plt.ylabel('Predicted Sale Price')

plt.plot([min(y_test1), max(y_test1)], [min(y_test1), max(y_test1)])
plt.tight_layout()

RMSE_xgb_hp = rmse_cv(modelo_xgb_hp, X_train1, y_train1)

print("RMSE-{}-CV({})={:06.5f}+-{:06.5f}".format('modelo_xgb_hp', folds, RMSE_xgb_hp.mean(), RMSE_xgb_hp.std()))
print('MAE:', mean_absolute_error(y_test1, xgb_hp_pred))
print('R2: ',  r2_score(y_test1, xgb_hp_pred) * 100)

#Aplico Cross-Validation para validar overfiting
xgb_hp_CV = cross_val_score(modelo_xgb_hp, X_train1, y_train1, scoring="neg_mean_squared_error", cv = 7)
print(xgb_hp_CV)

print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_xgb_hp', '7', xgb_hp_CV.mean()))
print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_xgb_hp', '7', xgb_hp_CV.std()))

# Predicción
xgb_hp_pred_log = modelo_xgb_hp.predict(X_test)
final_xgb_hp = pd.DataFrame({'Id':test_bis['Id'], 'SalePrice':np.expm1(xgb_hp_pred_log)})
final_xgb_hp.to_csv("/content/drive/MyDrive/Colab Notebooks/TFM/Data/final_xgb_hp.csv", index=False)

"""**Linear regression con hiperparametros - LASSO (LB: 3.94333)**"""

from sklearn import linear_model

# tunning
modelo_lasso_hp = linear_model.Lasso()

param_grid = {
    'alpha': [0.00001, 0.001, 0.1, 1, 10, 50, 100], 
    'max_iter': [100, 1000, 10000]
}

kfold = KFold(n_splits=folds, random_state=seed, shuffle=True)

scorer = make_scorer(rmse, greater_is_better=False)
grid_search = GridSearchCV(modelo_lasso_hp, param_grid, n_jobs=-1, cv=kfold, verbose=1, scoring=scorer)
grid_result = grid_search.fit(X_train1, y_train1)

means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']

for mean, stdev, param in zip(means, stds, params):
    print("{:06.5f} ({:06.5f}) with {}".format(mean, stdev, param))

# Resultados
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))

# Model
modelo_lasso_hp = linear_model.Lasso(alpha= 0.001, max_iter=100)

# Fit & Predict
modelo_lasso_hp.fit(X_train1, y_train1)
lasso_hp_pred = modelo_lasso_hp.predict(X_test1)

#Gráfica
sns.set(font_scale=1.5)
plt.figure(figsize=(10, 5))
plt.scatter(y_test1, lasso_hp_pred, s=20)
plt.title('Predicted vs. Actual')
plt.xlabel('Actual Sale Price')
plt.ylabel('Predicted Sale Price')

plt.plot([min(y_test1), max(y_test1)], [min(y_test1), max(y_test1)])
plt.tight_layout()

RMSE_lasso_hp = rmse_cv(modelo_lasso_hp, X_train1, y_train1)

print("RMSE-{}-CV({})={:06.5f}+-{:06.5f}".format('modelo_lasso_hp', folds, RMSE_lasso_hp.mean(), RMSE_lasso_hp.std()))
print('MAE:', mean_absolute_error(y_test1, lasso_hp_pred))
print('R2: ',  r2_score(y_test1, lasso_hp_pred) * 100)

#Aplico Cross-Validation para validar overfiting
lasso_hp_CV = cross_val_score(modelo_lasso_hp, X_train1, y_train1, scoring="neg_mean_squared_error", cv = 7)
print(lasso_hp_CV)

print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_lasso_hp', '7', lasso_hp_CV.mean()))
print("Cross Validation-{}-CV({})={:06.5f}".format('modelo_lasso_hp', '7', lasso_hp_CV.std()))

# Predicción
lasso_hp_pred_log = modelo_lasso_hp.predict(X_test)
final_lasso_hp = pd.DataFrame({'Id':test_bis['Id'], 'SalePrice':np.expm1(lasso_hp_pred_log)})
final_lasso_hp.to_csv("/content/drive/MyDrive/Colab Notebooks/TFM/Data/final_lasso_hp.csv", index=False)

"""#**Guardo el modelo**

Decido guardar el modelo para no tener que reentrenarlo nada vez que lo utilizo
"""

import joblib

modelo_final = modelo_RF_hp
joblib.dump(modelo_final, '/content/drive/MyDrive/Colab Notebooks/TFM/Data/modelo_RF_hp.pkl')

modelo_final = modelo_xgb
print(modelo_final)

import pickle
file_name = '/content/drive/MyDrive/Colab Notebooks/TFM/Data/modelo_final_xgb.pkl'
# save
pickle.dump(modelo_final, open(file_name, "wb"))